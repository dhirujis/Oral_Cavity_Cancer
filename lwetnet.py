# -*- coding: utf-8 -*-
"""LWETNet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mjGVjXMFx9_IhbTzzO7hcqXoEFonKZ2j
"""

import tensorflow as tf
from tensorflow.keras import layers, models, regularizers

def label_guided_attention(inputs, num_neighbors=8):
    projected_features = layers.Conv2D(64, (1, 1), padding='same')(inputs)
    distances = tf.keras.layers.Lambda(lambda x: tf.norm(
        tf.expand_dims(x, axis=-2) - tf.expand_dims(x, axis=-3), axis=-1))(projected_features)
    reduced_distances = layers.Conv2D(10, (1, 1), activation='gelu')(distances)
    transformed_distances = layers.Conv2D(64, (1, 1))(reduced_distances)
    affinities = tf.keras.layers.Softmax(axis=-2)(transformed_distances)
    # Explicitly define output shape for Lambda layer
    reconstructed_features = tf.keras.layers.Lambda(
        lambda x: tf.matmul(x[0], x[1]),
        output_shape=(inputs.shape[-3], inputs.shape[-2], inputs.shape[-1])  # Provide output shape here
    )([affinities, projected_features])
    output = layers.Add()([reconstructed_features, inputs])
    output = layers.BatchNormalization()(output)
    output = layers.ReLU()(output)
    return output


# CNN model with LGA
def create_label_guided_attention_network(input_shape, num_classes):
    inputs = layers.Input(shape=input_shape)
    x = layers.Conv2D(32, (3, 3), padding='same')(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)

    x = layers.Conv2D(64, (3, 3), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    x = layers.Conv2D(128, (3, 3), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)

    x = label_guided_attention(x)

    x = layers.Conv2D(256, (3, 3), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)

    x = label_guided_attention(x)

    x = layers.GlobalAveragePooling2D()(x)

    outputs = layers.Dense(num_classes, activation='softmax')(x)

    model = models.Model(inputs, outputs)
    return model
# Define input shape and number of classes
input_shape = (256, 256, 3)
num_classes = 7  # Change this to the number of classes in your dataset
# Create the model
model = create_label_guided_attention_network(input_shape, num_classes)
# Print model summary
model.summary()