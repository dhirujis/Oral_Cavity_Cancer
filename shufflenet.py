# -*- coding: utf-8 -*-
"""ShuffleNet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fsylyL5VjZTYBp5yNneQCcnbWVIfymL4
"""

import tensorflow as tf
from tensorflow.keras import layers, models

def channel_shuffle(x, groups):
    height, width, in_channels = x.shape[1:]
    channels_per_group = in_channels // groups

    # Reshape
    x = tf.reshape(x, [-1, height, width, groups, channels_per_group])
    # Transpose
    x = tf.transpose(x, [0, 1, 2, 4, 3])
    # Reshape
    x = tf.reshape(x, [-1, height, width, in_channels])

    return x

def shuffle_unit(inputs, in_channels, out_channels, groups, strides, stage, block):
    prefix = 'stage{}_block{}'.format(stage, block)

    if strides == 2:
        out_channels -= in_channels

    branch = inputs

    # 1x1 Group Convolution
    x = layers.Conv2D(in_channels, kernel_size=1, padding='same', use_bias=False, groups=groups, name=prefix + '_1_conv')(inputs)
    x = layers.BatchNormalization(name=prefix + '_1_bn')(x)
    x = layers.ReLU(name=prefix + '_1_relu')(x)

    # Channel Shuffle
    x = layers.Lambda(lambda z: channel_shuffle(z, groups), name=prefix + '_channel_shuffle')(x)

    # Depthwise Convolution
    x = layers.DepthwiseConv2D(kernel_size=3, strides=strides, padding='same', use_bias=False, name=prefix + '_depthwise_conv')(x)
    x = layers.BatchNormalization(name=prefix + '_depthwise_bn')(x)

    # 1x1 Group Convolution
    x = layers.Conv2D(out_channels, kernel_size=1, padding='same', use_bias=False, groups=groups, name=prefix + '_2_conv')(x)
    x = layers.BatchNormalization(name=prefix + '_2_bn')(x)

    if strides == 2:
        # Project the shortcut branch to match the number of channels and spatial dimensions in the main branch
        branch = layers.Conv2D(out_channels, kernel_size=1, strides=strides, padding='same', use_bias=False, name=prefix + '_proj_conv')(branch)
        branch = layers.BatchNormalization(name=prefix + '_proj_bn')(branch)

    # The average pooling should be applied outside the 'if' condition,
    # so it's always applied when strides == 1
    if strides == 2:
        x = layers.Concatenate(name=prefix + '_concat')([x, branch])
    else:
    x = layers.Add(name=prefix + '_add')([x, branch])

    x = layers.ReLU(name=prefix + '_out_relu')(x)

    return x
def create_shufflenet(input_shape, num_classes, scale_factor=1.0, groups=3):
    stages = [4, 8, 4]  # Number of blocks per stage
    out_channels = [24, 240, 480, 960]  # Output channels per stage

    out_channels = [int(c * scale_factor) for c in out_channels]

    inputs = layers.Input(shape=input_shape)
    x = layers.Conv2D(out_channels[0], kernel_size=3, strides=2, padding='same', use_bias=False, name='conv1')(inputs)
    x = layers.BatchNormalization(name='bn1')(x)
    x = layers.ReLU(name='relu1')(x)
    x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same', name='maxpool')(x)

    # ShuffleNet stages
    for stage in range(len(stages)):
        num_blocks = stages[stage]
        for block in range(num_blocks):
            strides = 2 if block == 0 and stage != 0 else 1
            x = shuffle_unit(x, in_channels=x.shape[-1], out_channels=out_channels[stage + 1], groups=groups, strides=strides, stage=stage + 2, block=block + 1)

    x = layers.GlobalAveragePooling2D(name='global_avg_pool')(x)
    outputs = layers.Dense(num_classes, activation='softmax', name='fc')(x)

    model = models.Model(inputs, outputs, name='ShuffleNet')
    return model

# Define input shape and number of classes
input_shape = (256, 256, 3)
num_classes = 7  # Change this to match the number of classes in your dataset

# Create the model
model = create_shufflenet(input_shape, num_classes, scale_factor=1.0, groups=3)


# Print model summary
model.summary()